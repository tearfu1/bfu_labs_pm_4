{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad30fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639f8633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from typing import Iterator, Tuple, Dict, List, Any\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "568b5eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAP ЭТАП ---\n",
    "def map_user_activity(row: Dict[str, Any]) -> Iterator[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Map функция: извлекает ID пользователя и поставленную им оценку.\n",
    "    \"\"\"\n",
    "    user_id = row.get('User_id', 'Unknown')\n",
    "    score = row.get('review/score', 0)\n",
    "    \n",
    "    # Пропускаем, если ID нет или оценка некорректна\n",
    "    if not isinstance(user_id, str) or user_id == 'Unknown':\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        score_float = float(score)\n",
    "        yield (user_id, score_float)\n",
    "    except (ValueError, TypeError):\n",
    "        return\n",
    "\n",
    "# --- SHUFFLE ЭТАП ---\n",
    "def shuffle_user_activity(mapped_data: Iterator[Tuple[str, float]]) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Shuffle функция: группирует все оценки по каждому пользователю.\n",
    "    \"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for user, score in mapped_data:\n",
    "        groups[user].append(score)\n",
    "    return groups\n",
    "\n",
    "# --- REDUCE ЭТАП ---\n",
    "def reduce_user_activity(grouped_data: Dict[str, List[float]]) -> List[Tuple[str, int, float]]:\n",
    "    \"\"\"\n",
    "    Reduce функция: считает количество рецензий и среднюю оценку для каждого пользователя.\n",
    "    Возвращает: (User_id, Количество рецензий, Средняя оценка)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for user, scores in grouped_data.items():\n",
    "        count = len(scores)\n",
    "        avg_score = sum(scores) / count if count > 0 else 0\n",
    "        results.append((user, count, avg_score))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de25008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MAP ЭТАП ---\n",
    "def map_publisher_rating(row: Dict[str, Any]) -> Iterator[Tuple[str, float]]:\n",
    "    \"\"\"\n",
    "    Map функция: извлекает Издателя и оценку.\n",
    "    \"\"\"\n",
    "    publisher = row.get('publisher', '')\n",
    "    score = row.get('review/score', 0)\n",
    "    \n",
    "    # Очистка данных: убираем пустые значения и мусор\n",
    "    if not isinstance(publisher, str) or not publisher.strip():\n",
    "        return\n",
    "        \n",
    "    try:\n",
    "        score_float = float(score)\n",
    "        # Немного приводим название к единому виду\n",
    "        clean_publisher = publisher.strip().strip(\"['\\\"]\")\n",
    "        yield (clean_publisher, score_float)\n",
    "    except (ValueError, TypeError):\n",
    "        return\n",
    "\n",
    "# --- SHUFFLE ЭТАП ---\n",
    "def shuffle_publisher_rating(mapped_data: Iterator[Tuple[str, float]]) -> Dict[str, List[float]]:\n",
    "    \"\"\"\n",
    "    Shuffle функция: группирует оценки по издателям.\n",
    "    \"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for pub, score in mapped_data:\n",
    "        groups[pub].append(score)\n",
    "    return groups\n",
    "\n",
    "# --- REDUCE ЭТАП ---\n",
    "def reduce_publisher_rating(grouped_data: Dict[str, List[float]], min_reviews: int = 5) -> List[Tuple[str, float, int]]:\n",
    "    \"\"\"\n",
    "    Reduce функция: считает средний рейтинг издательства.\n",
    "    Отсеиваем издательства, у которых мало отзывов (меньше min_reviews).\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for pub, scores in grouped_data.items():\n",
    "        if len(scores) >= min_reviews: # Фильтрация для достоверности\n",
    "            avg_score = sum(scores) / len(scores)\n",
    "            results.append((pub, avg_score, len(scores)))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f21380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Загрузка данных...\n",
      "Данные загружены. Размер: (50000, 11)\n"
     ]
    }
   ],
   "source": [
    "def load_dataset(limit: int = None) -> pd.DataFrame:\n",
    "    try:\n",
    "        print(\"Загрузка данных...\")\n",
    "        # Читаем основные файлы\n",
    "        df_reviews = pd.read_csv('Books_rating.csv')\n",
    "        df_meta = pd.read_csv('Books_data.csv')\n",
    "        \n",
    "        # Для анализа издательств нам нужен Merge двух таблиц по названию книги (Title)\n",
    "        # Используем left join, чтобы не потерять рецензии\n",
    "        merged_df = pd.merge(df_reviews, df_meta[['Title', 'publisher']], on='Title', how='left')\n",
    "        \n",
    "        if limit:\n",
    "            return merged_df.head(limit)\n",
    "        return merged_df\n",
    "        \n",
    "    except FileNotFoundError:\n",
    "        print(\"Файлы не найдены! Убедитесь, что dataset скачан с Kaggle.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Загружаем часть данных для демонстрации\n",
    "df = load_dataset(limit=50000)\n",
    "print(f\"Данные загружены. Размер: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe53d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ЗАДАЧА 1: ТОП АКТИВНЫХ ПОЛЬЗОВАТЕЛЕЙ ===\n",
      "USER ID              | COUNT      | AVG SCORE \n",
      "---------------------------------------------\n",
      "A14OJS0VWMOSWO       | 99         | 5.00\n",
      "AFVQZQ8PW0L          | 46         | 4.67\n",
      "A1D2C0WDCSHUWZ       | 43         | 4.60\n",
      "A1L43KWWR05PCS       | 41         | 4.41\n",
      "AHD101501WCN1        | 39         | 4.59\n",
      "A1X8VZWTOG8IS6       | 35         | 3.80\n",
      "A20EEWWSFMZ1PN       | 30         | 4.93\n",
      "A1EKTLUL24HDG8       | 27         | 4.67\n",
      "A3MV1KKHX51FYT       | 23         | 4.30\n",
      "A1N1YEMTI9DJ86       | 23         | 4.52\n",
      "\n",
      "\n",
      "=== ЗАДАЧА 2: ТОП КАЧЕСТВЕННЫХ ИЗДАТЕЛЬСТВ ===\n",
      "PUBLISHER                                | RATING     | REVIEWS   \n",
      "-----------------------------------------------------------------\n",
      "Longtail Publishing                      | 5.00       | 22        \n",
      "University of Central Florida            | 5.00       | 10        \n",
      "Thomas Nelson                            | 5.00       | 11        \n",
      "Dial Press Trade Paperback               | 5.00       | 15        \n",
      "University of Texas Press                | 5.00       | 10        \n",
      "Anova Books                              | 5.00       | 12        \n",
      "e-artnow                                 | 5.00       | 21        \n",
      "Sylvia Engdahl                           | 5.00       | 22        \n",
      "McKenna Publishing Group                 | 5.00       | 11        \n",
      "CLC Publications                         | 5.00       | 20        \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== ЗАДАЧА 1: ТОП АКТИВНЫХ ПОЛЬЗОВАТЕЛЕЙ ===\")\n",
    "# 1. Map\n",
    "mapped_users = []\n",
    "for _, row in df.iterrows():\n",
    "    mapped_users.extend(map_user_activity(row))\n",
    "\n",
    "# 2. Shuffle\n",
    "shuffled_users = shuffle_user_activity(iter(mapped_users))\n",
    "\n",
    "# 3. Reduce\n",
    "reduced_users = reduce_user_activity(shuffled_users)\n",
    "\n",
    "# 4. Ранжирование (Ranking)\n",
    "top_users = sorted(reduced_users, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(f\"{'USER ID':<20} | {'COUNT':<10} | {'AVG SCORE':<10}\")\n",
    "print(\"-\" * 45)\n",
    "for user, count, avg in top_users:\n",
    "    print(f\"{user[:18]:<20} | {count:<10} | {avg:.2f}\")\n",
    "\n",
    "\n",
    "print(\"\\n\\n=== ЗАДАЧА 2: ТОП КАЧЕСТВЕННЫХ ИЗДАТЕЛЬСТВ ===\")\n",
    "# 1. Map\n",
    "mapped_pubs = []\n",
    "for _, row in df.iterrows():\n",
    "    mapped_pubs.extend(map_publisher_rating(row))\n",
    "\n",
    "# 2. Shuffle\n",
    "shuffled_pubs = shuffle_publisher_rating(iter(mapped_pubs))\n",
    "\n",
    "# 3. Reduce\n",
    "reduced_pubs = reduce_publisher_rating(shuffled_pubs, min_reviews=10)\n",
    "\n",
    "# 4. Ранжирование (Ranking)\n",
    "top_publishers = sorted(reduced_pubs, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "print(f\"{'PUBLISHER':<40} | {'RATING':<10} | {'REVIEWS':<10}\")\n",
    "print(\"-\" * 65)\n",
    "for pub, rating, count in top_publishers:\n",
    "    print(f\"{pub[:38]:<40} | {rating:.2f}       | {count:<10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
